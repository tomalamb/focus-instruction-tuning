<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Focus On This, Not That! Steering LLMs With Adaptive Feature Specification</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Focus On This, Not That! Steering LLMs With Adaptive Feature Specification</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://tomalamb.github.io/" target="_blank">Tom A. Lamb</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="https://ahdavies6.github.io/" target="_blank">Adam Davies</a><sup>2</sup>,</span>
                  <span class="author-block">
                    <a href="https://alasdair-p.github.io/Alasdair-P/" target="_blank">Alasdair Paren</a><sup>1</sup>,</span>
                    <span class="author-block">
                      <a href="https://www.robots.ox.ac.uk/~phst/" target="_blank">Philip H.S. Torr</a><sup>1</sup>,</span>
                      <span class="author-block">
                        <a href="https://scholar.google.com/citations?user=rqAdo2MAAAAJ&hl=en" target="_blank">Francesco Pinto</a><sup>3</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">University of Oxford<sup>1</sup>, University of Illinois Urbana-Champaign<sup>2</sup>, and University of Chicago<sup>3</sup><br>ICML 2025, Vancouver</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2410.22944.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    
                    <!-- Github link -->
                    <span class="link-block">
                      <a href="https://github.com/YOUR REPO HERE" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                  </span>

                  <!-- Hugging face dataset -->
                  <span class="link-block">
                    <a href="https://huggingface.co/tomalamb" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-hf"></i>
                    </span>
                    <span>Datasets</span>
                  </a>
                </span>

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Despite the success of Instruction Tuning (IT) in training large language models (LLMs), such models often leverage spurious or biased features learnt from their training data and can become misaligned, leading to undesired behaviours. While existing techniques can steer model behaviour at inference-time, they are often post-hoc and do not embed steering as an intrinsic model feature. In this work, we introduce Focus Instruction Tuning (FIT), which trains LLMs to condition their responses by focusing on specific features whilst ignoring others, leading to different behaviours based on what features are specified. Across diverse benchmarks, we demonstrate that FIT: (i) successfully steers behaviour at inference time; (ii) increases robustness by amplifying core task signals and down-weighting spurious cues; (iii) mitigates social bias by suppressing demographic attributes; and (iv) generalises under distribution shifts and to previously unseen focus features. FIT therefore offers a lightweight, intrinsic mechanism for building more robust, fair, and easily controllable LLMs.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Motivation Image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <figure class="image is-square">
        <img
          src="static/images/motivation.png"
          alt="Teaser Image"
        >
      </figure>
      <strong>Focus Instruction Tuning (FIT).</strong> In the example above...
    </div>
  </div>
</section>
<!-- End Motivation Image-->
 
<!-- Lay Summary -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Lay Summary</h2>
        <div class="content has-text-justified">
          <p>
            Large language models (LLMs), like those powering chatbots, are trained to follow instructions. However, further training of such models to solve specific tasks can sometimes cause them to overlook important goals such as safety or fairness. For instance, if a model is fine-tuned to be more helpful, it might start providing sensitive information or inappropriately reinforce social biases. While some existing techniques can adjust how a model acts after training, these methods are often complicated, difficult to use, and don’t let everyday users easily guide the model with plain natural language.

To address this, we propose **focus-instruction-tuning (FIT)**: a new technique that lets users adaptively control a model’s responses using simple, natural language instructions at the time of use. For example, a user could include, “Answer this question without using gender stereotypes” directly in their prompt, and the model will adapt its response accordingly, helping to correct misalignments such as gender bias that can result from training.

Our findings show that FIT makes language models more flexible and dependable. It allows them to follow new instructions across a wide range of situations, helps reduce unwanted bias in their answers, and continues to work well even when faced with new topics or unexpected changes in data.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Lay Summary  -->

<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/focus_labels.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
    
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/SMNLI_dgp.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
       
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/smnli_results.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
   
       </h2>
     </div>
     <div class="item">
      <!-- Your image here -->
      <img src="static/images/bbq_results.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">

      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->



<!-- # TODO: Add paper poster here -->
<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{lamb2024focus,
  title={Focus On This, Not That! Steering LLMs With Adaptive Feature Specification},
  author={Lamb, Tom A and Davies, Adam and Paren, Alasdair and Torr, Philip HS and Pinto, Francesco},
  journal={arXiv preprint arXiv:2410.22944},
  year={2024}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
